{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fitting SVM to homological representation\n",
        "\n",
        "This notebook follows the Lecture 16 idea: compute a homological representation of data and fit an SVM with a precomputed kernel.\n",
        "\n",
        "We will:\n",
        "- Load STFT domain-frequency data from `stft_np/` using the provided `meta.json` and memmaps.\n",
        "- For each sample, build a 2D point cloud from frequency vs magnitude and compute persistence diagrams (ripser).\n",
        "- Convert diagrams to barcodes and then to stable rank functions using the provided `stablerank` utilities.\n",
        "- Build a kernel matrix using Pcf/Pcnif dot-products and fit `sklearn.svm.SVC(kernel='precomputed')`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((940, 1000, 257), (973, 1000, 257), (257,))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Data locations\n",
        "ROOT = \"/Users/theodorbjork/SF2956\"\n",
        "STFT_DIR = os.path.join(ROOT, \"stft_np\")\n",
        "META_FP = os.path.join(STFT_DIR, \"meta.json\")\n",
        "\n",
        "# Load metadata and memmaps\n",
        "with open(META_FP, \"r\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "A = np.memmap(os.path.join(STFT_DIR, meta[\"A_memmap\"]), dtype=np.float16, mode=\"r\", shape=tuple(meta[\"A_shape\"]))\n",
        "B = np.memmap(os.path.join(STFT_DIR, meta[\"B_memmap\"]), dtype=np.float16, mode=\"r\", shape=tuple(meta[\"B_shape\"]))\n",
        "freqs = np.load(os.path.join(STFT_DIR, meta[\"freqs_npy\"]))\n",
        "\n",
        "A.shape, B.shape, freqs.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((160, 1000, 257), (160,), array([80, 80]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build labels and a light subset to start (keep runtime manageable)\n",
        "# Using first N from each class\n",
        "N_PER_CLASS = 80\n",
        "\n",
        "XA = A[:N_PER_CLASS].astype(np.float32)\n",
        "XB = B[:N_PER_CLASS].astype(np.float32)\n",
        "X = np.concatenate([XA, XB], axis=0)   # (n, frames, bins)\n",
        "y = np.concatenate([np.ones(len(XA), dtype=np.int64), np.zeros(len(XB), dtype=np.int64)])\n",
        "\n",
        "X.shape, y.shape, np.bincount(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(160, 1000, 257) (160,) [80 80]\n"
          ]
        }
      ],
      "source": [
        "# Compatibility aliases (some cells may reference X_small/y_small)\n",
        "X_small = X\n",
        "y_small = y\n",
        "print(X_small.shape, y_small.shape, np.bincount(y_small))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Homological representation utilities\n",
        "# We'll compute a simple persistence on a downsampled slice per sample.\n",
        "\n",
        "!pip -q install ripser scikit-learn\n",
        "\n",
        "from ripser import ripser\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Convert a 2D time-frequency patch into a point cloud in R^2\n",
        "# We use (frequency, magnitude) pairs sampled over time window(s)\n",
        "\n",
        "def stft_patch_to_points(stft_patch: np.ndarray, freqs: np.ndarray, time_stride: int = 20, freq_stride: int = 4, top_k: int = 32):\n",
        "    # stft_patch: (frames, bins) in dB [-80, 0]\n",
        "    fidx = np.arange(0, stft_patch.shape[1], freq_stride)\n",
        "    tidx = np.arange(0, stft_patch.shape[0], time_stride)\n",
        "    pts = []\n",
        "    for t in tidx:\n",
        "        row = stft_patch[t, fidx]\n",
        "        # pick top-k magnitudes at this time\n",
        "        k = min(top_k, row.size)\n",
        "        idx = np.argpartition(row, -k)[-k:]\n",
        "        sel_freqs = freqs[fidx][idx]\n",
        "        sel_mags  = row[idx]\n",
        "        pts.append(np.stack([sel_freqs, sel_mags], axis=1))\n",
        "    if len(pts) == 0:\n",
        "        return np.zeros((0, 2), dtype=np.float32)\n",
        "    P = np.concatenate(pts, axis=0)\n",
        "    # normalize scales for balance (freq Hz -> kHz; mags in dB -> scaled)\n",
        "    P = P.astype(np.float32)\n",
        "    P[:, 0] = P[:, 0] / 1000.0\n",
        "    P[:, 1] = (P[:, 1] + 80.0) / 80.0  # [-80,0] -> [0,1]\n",
        "    return P\n",
        "\n",
        "\n",
        "def persistence_vector(points: np.ndarray, maxdim: int = 1):\n",
        "    if points.shape[0] == 0:\n",
        "        return {\"dgms\": []}\n",
        "    res = ripser(points, maxdim=maxdim, metric='euclidean')\n",
        "    return res\n",
        "\n",
        "\n",
        "def wasserstein_kernel(diagrams_a, diagrams_b, gamma: float = 0.5):\n",
        "    # Simple RBF on pairwise L2 between flattened finite bars of H0 and H1\n",
        "    def flatten(dgms):\n",
        "        flat = []\n",
        "        for d in dgms:\n",
        "            if len(d) == 0:\n",
        "                continue\n",
        "            d = d[np.isfinite(d).all(axis=1)]\n",
        "            flat.append(d.reshape(-1))\n",
        "        if not flat:\n",
        "            return np.zeros((0,), dtype=np.float32)\n",
        "        return np.concatenate(flat).astype(np.float32)\n",
        "    a = flatten(diagrams_a)\n",
        "    b = flatten(diagrams_b)\n",
        "    # Pad to same length\n",
        "    m = max(a.size, b.size)\n",
        "    a = np.pad(a, (0, m - a.size))\n",
        "    b = np.pad(b, (0, m - b.size))\n",
        "    dist2 = np.sum((a - b) ** 2)\n",
        "    return np.exp(-gamma * dist2)\n",
        "\n",
        "\n",
        "def build_kernel_matrix(X_list, freqs, maxdim=1, gamma=0.25):\n",
        "    # Precompute diagrams\n",
        "    diagrams = []\n",
        "    for x in tqdm(X_list, desc=\"Ripser diagrams\"):\n",
        "        # Take middle 200 frames as a robust slice\n",
        "        mid = x.shape[0] // 2\n",
        "        start = max(0, mid - 100)\n",
        "        end = min(x.shape[0], start + 200)\n",
        "        patch = x[start:end]\n",
        "        P = stft_patch_to_points(patch, freqs)\n",
        "        res = persistence_vector(P, maxdim=maxdim)\n",
        "        dgms = [res.get(\"dgms\", [])[i] if i < len(res.get(\"dgms\", [])) else np.zeros((0, 2)) for i in range(maxdim + 1)]\n",
        "        diagrams.append(dgms)\n",
        "    n = len(diagrams)\n",
        "    K = np.zeros((n, n), dtype=np.float64)\n",
        "    for i in range(n):\n",
        "        K[i, i] = 1.0\n",
        "        for j in range(i + 1, n):\n",
        "            kij = wasserstein_kernel(diagrams[i], diagrams[j], gamma=gamma)\n",
        "            K[i, j] = K[j, i] = kij\n",
        "    return K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ripser diagrams: 100%|██████████| 160/160 [00:05<00:00, 28.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel shape: (160, 160) min/max: 1.1290040084247468e-34 1.0\n",
            "Holdout accuracy: 0.625\n"
          ]
        }
      ],
      "source": [
        "# Build precomputed kernel and train/test SVM with a simple holdout\n",
        "K = build_kernel_matrix(list(X), freqs, maxdim=1, gamma=0.25)\n",
        "print(\"Kernel shape:\", K.shape, \"min/max:\", K.min(), K.max())\n",
        "\n",
        "# Split indices and slice precomputed kernel accordingly\n",
        "n = K.shape[0]\n",
        "all_idx = np.arange(n)\n",
        "tr_idx, te_idx = train_test_split(all_idx, test_size=0.25, stratify=y, random_state=42)\n",
        "\n",
        "Ktr = K[np.ix_(tr_idx, tr_idx)]\n",
        "Kte = K[np.ix_(te_idx, tr_idx)]\n",
        "\n",
        "ytr = y[tr_idx]\n",
        "yte = y[te_idx]\n",
        "\n",
        "clf = SVC(kernel='precomputed', C=1.0)\n",
        "clf.fit(Ktr, ytr)\n",
        "print(\"Holdout accuracy:\", round(clf.score(Kte, yte), 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fitting SVM to homological representation\n",
        "\n",
        "This notebook follows the Lecture 16 idea: compute a homological representation of data and fit an SVM with a precomputed kernel.\n",
        "\n",
        "We will:\n",
        "- Load STFT domain-frequency data from `stft_np/` using the provided `meta.json` and memmaps.\n",
        "- For each sample, build a 2D point cloud from frequency vs magnitude and compute persistence diagrams (ripser).\n",
        "- Convert diagrams to barcodes and then to stable rank functions using the provided `stablerank` utilities.\n",
        "- Build a kernel matrix using Pcf/Pcnif dot-products and fit `sklearn.svm.SVC(kernel='precomputed')`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((940, 1000, 257), (973, 1000, 257), (257,))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Data locations\n",
        "ROOT = \"/Users/theodorbjork/SF2956\"\n",
        "STFT_DIR = os.path.join(ROOT, \"stft_np\")\n",
        "META_FP = os.path.join(STFT_DIR, \"meta.json\")\n",
        "\n",
        "# Load metadata and memmaps\n",
        "with open(META_FP, \"r\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "A = np.memmap(os.path.join(STFT_DIR, meta[\"A_memmap\"]), dtype=np.float16, mode=\"r\", shape=tuple(meta[\"A_shape\"]))\n",
        "B = np.memmap(os.path.join(STFT_DIR, meta[\"B_memmap\"]), dtype=np.float16, mode=\"r\", shape=tuple(meta[\"B_shape\"]))\n",
        "freqs = np.load(os.path.join(STFT_DIR, meta[\"freqs_npy\"]))\n",
        "\n",
        "A.shape, B.shape, freqs.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((400, 1000, 257), (400,), array([200, 200]))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build labels and a light subset to start (keep runtime manageable)\n",
        "# Using first N from each class\n",
        "N_PER_CLASS = 200  # increase to use more data\n",
        "\n",
        "XA = A[:N_PER_CLASS].astype(np.float32)\n",
        "XB = B[:N_PER_CLASS].astype(np.float32)\n",
        "X = np.concatenate([XA, XB], axis=0)   # (n, frames, bins)\n",
        "y = np.concatenate([np.ones(len(XA), dtype=np.int64), np.zeros(len(XB), dtype=np.int64)])\n",
        "\n",
        "X.shape, y.shape, np.bincount(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ripser diagrams: 100%|██████████| 400/400 [00:16<00:00, 24.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel shape: (400, 400)\n",
            "Train/Test label counts: [150 150] [50 50]\n",
            "Holdout accuracy: 0.57\n"
          ]
        }
      ],
      "source": [
        "# Build precomputed kernel on X and train/test SVM\n",
        "K = build_kernel_matrix(list(X), freqs, maxdim=1, gamma=0.25)\n",
        "print(\"Kernel shape:\", K.shape)\n",
        "\n",
        "# Sanity: labels exist and match K\n",
        "n = K.shape[0]\n",
        "assert n == X.shape[0]\n",
        "assert np.array_equal(np.unique(y), np.array([0,1])), np.unique(y)\n",
        "\n",
        "# Stratified split on indices, then slice K and y consistently\n",
        "idx = np.arange(n)\n",
        "tr_idx, te_idx = train_test_split(idx, test_size=0.25, stratify=y, random_state=42)\n",
        "print(\"Train/Test label counts:\", np.bincount(y[tr_idx]), np.bincount(y[te_idx]))\n",
        "assert len(np.unique(y[tr_idx])) == 2 and len(np.unique(y[te_idx])) == 2\n",
        "\n",
        "Ktr = K[np.ix_(tr_idx, tr_idx)]\n",
        "Kte = K[np.ix_(te_idx, tr_idx)]\n",
        "ytr, yte = y[tr_idx], y[te_idx]\n",
        "\n",
        "clf = SVC(kernel='precomputed', C=1.0)\n",
        "clf.fit(Ktr, ytr)\n",
        "print(\"Holdout accuracy:\", round(clf.score(Kte, yte), 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Homological representation utilities\n",
        "# We'll compute a simple persistence on a downsampled slice per sample.\n",
        "\n",
        "!pip -q install ripser scikit-learn\n",
        "\n",
        "from ripser import ripser\n",
        "from sklearn.metrics.pairwise import pairwise_kernels\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Convert a 2D time-frequency patch into a point cloud in R^2\n",
        "# We use (frequency, magnitude) pairs sampled over time window(s)\n",
        "\n",
        "def stft_patch_to_points(stft_patch: np.ndarray, freqs: np.ndarray, time_stride: int = 20, freq_stride: int = 4, top_k: int = 32):\n",
        "    # stft_patch: (frames, bins) in dB [-80, 0]\n",
        "    fidx = np.arange(0, stft_patch.shape[1], freq_stride)\n",
        "    tidx = np.arange(0, stft_patch.shape[0], time_stride)\n",
        "    pts = []\n",
        "    for t in tidx:\n",
        "        row = stft_patch[t, fidx]\n",
        "        # pick top-k magnitudes at this time\n",
        "        k = min(top_k, row.size)\n",
        "        idx = np.argpartition(row, -k)[-k:]\n",
        "        sel_freqs = freqs[fidx][idx]\n",
        "        sel_mags  = row[idx]\n",
        "        pts.append(np.stack([sel_freqs, sel_mags], axis=1))\n",
        "    if len(pts) == 0:\n",
        "        return np.zeros((0, 2), dtype=np.float32)\n",
        "    P = np.concatenate(pts, axis=0)\n",
        "    # normalize scales for balance (freq Hz -> kHz; mags in dB -> scaled)\n",
        "    P = P.astype(np.float32)\n",
        "    P[:, 0] = P[:, 0] / 1000.0\n",
        "    P[:, 1] = (P[:, 1] + 80.0) / 80.0  # [-80,0] -> [0,1]\n",
        "    return P\n",
        "\n",
        "\n",
        "def persistence_vector(points: np.ndarray, maxdim: int = 1):\n",
        "    if points.shape[0] == 0:\n",
        "        return {\"dgms\": []}\n",
        "    res = ripser(points, maxdim=maxdim, metric='euclidean')\n",
        "    return res\n",
        "\n",
        "\n",
        "def wasserstein_kernel(diagrams_a, diagrams_b, p: int = 2, gamma: float = 1.0):\n",
        "    # Simple RBF on pairwise L2 between flattened finite bars of H0 and H1\n",
        "    def flatten(dgms):\n",
        "        flat = []\n",
        "        for d in dgms:\n",
        "            if len(d) == 0:\n",
        "                continue\n",
        "            d = d[np.isfinite(d).all(axis=1)]\n",
        "            flat.append(d.reshape(-1))\n",
        "        if not flat:\n",
        "            return np.zeros((0,), dtype=np.float32)\n",
        "        return np.concatenate(flat).astype(np.float32)\n",
        "    a = flatten(diagrams_a)\n",
        "    b = flatten(diagrams_b)\n",
        "    # Pad to same length\n",
        "    m = max(a.size, b.size)\n",
        "    a = np.pad(a, (0, m - a.size))\n",
        "    b = np.pad(b, (0, m - b.size))\n",
        "    dist2 = np.sum((a - b) ** 2)\n",
        "    return np.exp(-gamma * dist2)\n",
        "\n",
        "\n",
        "def build_kernel_matrix(X_list, freqs, maxdim=1, gamma=0.5):\n",
        "    # Precompute diagrams\n",
        "    diagrams = []\n",
        "    for x in tqdm(X_list, desc=\"Ripser diagrams\"):\n",
        "        # Take middle 200 frames as a robust slice\n",
        "        mid = x.shape[0] // 2\n",
        "        start = max(0, mid - 100)\n",
        "        end = min(x.shape[0], start + 200)\n",
        "        patch = x[start:end]\n",
        "        P = stft_patch_to_points(patch, freqs)\n",
        "        res = persistence_vector(P, maxdim=maxdim)\n",
        "        dgms = [res.get(\"dgms\", [])[i] if i < len(res.get(\"dgms\", [])) else np.zeros((0, 2)) for i in range(maxdim + 1)]\n",
        "        diagrams.append(dgms)\n",
        "    n = len(diagrams)\n",
        "    K = np.zeros((n, n), dtype=np.float64)\n",
        "    for i in range(n):\n",
        "        K[i, i] = 1.0\n",
        "        for j in range(i + 1, n):\n",
        "            kij = wasserstein_kernel(diagrams[i], diagrams[j], gamma=gamma)\n",
        "            K[i, j] = K[j, i] = kij\n",
        "    return K\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ripser diagrams: 100%|██████████| 120/120 [00:03<00:00, 37.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel shape: (120, 120) min/max: 5.285725150127048e-20 1.0\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "The number of classes has to be greater than one; got 1 class",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m Kte \u001b[38;5;241m=\u001b[39m K[np\u001b[38;5;241m.\u001b[39mix_(ite, itr)]\n\u001b[1;32m     22\u001b[0m clf \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m acc \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mscore(Kte, yte)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHoldout accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(acc, \u001b[38;5;241m4\u001b[39m))\n",
            "File \u001b[0;32m~/SF2956/.venv/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/SF2956/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py:207\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    199\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    205\u001b[0m     )\n\u001b[0;32m--> 207\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[1;32m    210\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    211\u001b[0m )\n\u001b[1;32m    212\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
            "File \u001b[0;32m~/SF2956/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py:751\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 751\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of classes has to be greater than one; got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m class\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    754\u001b[0m     )\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
          ]
        }
      ],
      "source": [
        "# Build precomputed kernel and train/test SVM with CV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Downselect further if needed to speed up\n",
        "MAX_N = 120\n",
        "if X.shape[0] > MAX_N:\n",
        "    X_small = X[:MAX_N]\n",
        "    y_small = y[:MAX_N]\n",
        "else:\n",
        "    X_small, y_small = X, y\n",
        "\n",
        "K = build_kernel_matrix(list(X_small), freqs, maxdim=1, gamma=0.25)\n",
        "print(\"Kernel shape:\", K.shape, \"min/max:\", K.min(), K.max())\n",
        "\n",
        "# Simple holdout\n",
        "idx = np.arange(K.shape[0])\n",
        "Xtr, Xte, ytr, yte, itr, ite = train_test_split(K, y_small, idx, test_size=0.25, stratify=y_small, random_state=42)\n",
        "# For precomputed kernel, pass the submatrices appropriately\n",
        "Ktr = K[np.ix_(itr, itr)]\n",
        "Kte = K[np.ix_(ite, itr)]\n",
        "\n",
        "clf = SVC(kernel='precomputed', C=1.0)\n",
        "clf.fit(Ktr, ytr)\n",
        "acc = clf.score(Kte, yte)\n",
        "print(\"Holdout accuracy:\", round(acc, 4))\n",
        "\n",
        "# Cross-validation on full K\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = []\n",
        "for tr, te in cv.split(K, y_small):\n",
        "    Ktr = K[np.ix_(tr, tr)]\n",
        "    Kte = K[np.ix_(te, tr)]\n",
        "    clf = SVC(kernel='precomputed', C=1.0)\n",
        "    clf.fit(Ktr, y_small[tr])\n",
        "    scores.append(clf.score(Kte, y_small[te]))\n",
        "print(\"CV scores:\", [round(s, 4) for s in scores], \"| mean=\", round(float(np.mean(scores)), 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
